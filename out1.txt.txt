key portions of real applications (e. g. digital ﬁltering
algorithms).

I T eclznology-speciﬁc benchmarks are devoted to point
out the main differences of devices belonging to the
same technological family (e.g. Programmable
Electronic Performance Cooperative or PREP
benchmarks [7]).

Application and synthetic benchmarks tend to assess the
behavior of a processing device when different types of
operations are carried out. Accordingly, these kinds of
benchmarks are suitable to estimate the average performance
of very involved, general-purpose systems (e.g. personal
computers), but they are unable to provide signiﬁcant results
when single devices have to implement a speciﬁc set of
algorithms, as it usually occurs in most digital signal
processing applications. On the other hand, technology-
speciﬁc benchmarks are usually so specialized not to be
useful for cross-technology comparisons. As a consequence,
only kernel benchmarks are suitable to estimate univocally the
performances of different digital signal processing solutions.
Generally, a well-designed kernel benchmark test has to be:

I representative: the performance result should be
summarized by a single number, usually referred to as
index of performance;

I reliable: the larger the index of performance is, the
faster the device under test (DUT) has to be;

I reproducible: running several times the same
benchmark program on a given device under the same
conditions, performance results should not change
considerably (except for uncertainty contributions);

I portable: the benchmark has to be independent of a
particular technology or architecture.

Besides these basic properties, a kernel benchmark test

should also be:

I meaningful, because it is pointless to measure an
uninteresting or rarely used feature;

I linear: any index should be proportional to real
performance;

I easy to use so that it can be used frequently and
correctly;

I vendor independent, i.e. independent as much as
possible of the inﬂuence of external subjects which
may be interested in benchmarking results (e.g. for
marketing purposes).

Some published results suggest that performance indexes
referring to digital signal processing devices can be
effectively measured by means of basic algorithms such as
numeric ﬁltering, FFT, matrix calculations or operations on
bit streams [3, 4]. Among them, FFT algorithms are most
valuable benchmarks because they own all the properties
mentioned above. In fact, FFT benchmarking is:

I representative because several numerical indexes can

be calculated from FFT processing times;

I reliable as processing time does not depend on the
kind of input data;

I reproducible because execution time associated with
a given device depends only on the algorithm chosen
and on the clock frequency [5];

I portable: FFT is basically a mathematical operation;

I meaningful because FFT is widely used in many
digital signal processing applications;

I linear: doubling the performance means halving the
execution time (or doubling data rate as explained in
next section);

I easy to use because, once FFT is implemented, only
transformation times need to be measured regardless
of input values;

I vendor independent as standard FFT algorithms are
not proprietary.

Besides these features, plenty of documentation is
available about different FFT implementations both in terms
of design choices and performance analyses. Hence, using a
given FFT algorithm as a kernel benchmark not only eases
the comparison between devices belonging to different
technologies, but allows also verifying the truthfulness of the
performance claimed by device manufacturers.

3. PERFORMANCE METRICS

Basically, the performance of any digital signal
processing application can be measured in terms of data rate
(DR), which is referred to as:

N
DR 2 —
t

proc

[samples/s] , (l)

where N is the amount of processed samples and tpm. is the
processing time (e.g. the time to compute an FFT algorithm
on N=1024 complex samples). Notice that this parameter is
reliable because it is inversely proportional to the processing
time, so that its value grows linearly with performance, as
expected intuitively. An equivalent index to express the
processing capabilities of a given digital signal processing
device is the so-called Real-Time Bandwidth (RTBW) that
represents the maximum bandwidth with which an effective
analog input signal can be processed in real-time, without
loss of information. According to the Nyquist theorem [4],
RT BWis numerically equal to half of DR, provided that tpm.
is the effective FFT processing time, i.e. it is not affected by
bus overhead or latencies associated with external memory
operations. Under these assumptions, once FFT algorithm has
been chosen, the estimated RT BW value depends only on the
characteristics of the DUT, such as the clock frequency and
the operation execution speed. Conversely, if FFT
computation time is slowed down by poor bus performance or
by other system bottlenecks, the RT BW value provided by (1)
could be appreciably overestimated.

In addition to RBT W, another valuable parameter to assess
the performance of a digital signal processing device is the
Architectural Efﬁciency (AE), which is referred to as:

